{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-10T01:11:27.092048Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"facebook/voxpopuli\", \"nl\", split=\"train\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a7b5b9c784eff6a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "cec4cdd03f20adf1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ed3ceb6c96908c43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = processor.tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2915197696c07ae1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"normalized_text\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "vocabs = dataset.map(\n",
    "    extract_all_chars, \n",
    "    batched=True, \n",
    "    batch_size=-1, \n",
    "    keep_in_memory=True, \n",
    "    remove_columns=dataset.column_names,\n",
    ")\n",
    "\n",
    "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
    "tokenizer_vocab = {k for k,_ in tokenizer.get_vocab().items()}"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "83058c87d5113005"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_vocab - tokenizer_vocab"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "84f9bc8d528511c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "replacements = [\n",
    "    ('à', 'a'),\n",
    "    ('ç', 'c'),\n",
    "    ('è', 'e'),\n",
    "    ('ë', 'e'),\n",
    "    ('í', 'i'),\n",
    "    ('ï', 'i'),\n",
    "    ('ö', 'o'),\n",
    "    ('ü', 'u'),\n",
    "]\n",
    "\n",
    "def cleanup_text(inputs):\n",
    "    for src, dst in replacements:\n",
    "        inputs[\"normalized_text\"] = inputs[\"normalized_text\"].replace(src, dst)\n",
    "    return inputs\n",
    "\n",
    "dataset = dataset.map(cleanup_text)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "90c9f9c3d248c68c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "speaker_counts = defaultdict(int)\n",
    "\n",
    "for speaker_id in dataset[\"speaker_id\"]:\n",
    "    speaker_counts[speaker_id] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d92678ddcea5f9cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(speaker_counts.values(), bins=20)\n",
    "plt.ylabel(\"Speakers\")\n",
    "plt.xlabel(\"Examples\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "47e7b608e3d060e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def select_speaker(speaker_id):\n",
    "    return 100 <= speaker_counts[speaker_id] <= 400\n",
    "\n",
    "dataset = dataset.filter(select_speaker, input_columns=[\"speaker_id\"])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "feb6656000aabd40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(set(dataset[\"speaker_id\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fc9b627cab8f41c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4ab79d1870911369"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "\n",
    "spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "speaker_model = EncoderClassifier.from_hparams(\n",
    "    source=spk_model_name, \n",
    "    run_opts={\"device\": device}, \n",
    "    savedir=os.path.join(\"/tmp\", spk_model_name)\n",
    ")\n",
    "\n",
    "def create_speaker_embedding(waveform):\n",
    "    with torch.no_grad():\n",
    "        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n",
    "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
    "        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n",
    "    return speaker_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bcecce95c9469709"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_dataset(example):\n",
    "    # load the audio data; if necessary, this resamples the audio to 16kHz\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    # feature extraction and tokenization\n",
    "    example = processor(\n",
    "        text=example[\"normalized_text\"],\n",
    "        audio_target=audio[\"array\"], \n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        return_attention_mask=False,\n",
    "    )\n",
    "\n",
    "    # strip off the batch dimension\n",
    "    example[\"labels\"] = example[\"labels\"][0]\n",
    "\n",
    "    # use SpeechBrain to obtain x-vector\n",
    "    example[\"speaker_embeddings\"] = create_speaker_embedding(audio[\"array\"])\n",
    "\n",
    "    return example"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "99fccdcd026a6eed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processed_example = prepare_dataset(dataset[0]) "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2bc28161cd44f8b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3909d35b08199aff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
